# .github/workflows/package_torchscript.yml
#
# GitHub Action: Exports prior_depth_anything_vitb.pt and uploads it as an artifact.
# -- The TorchScript is compiled with *torch-1.12.1 CPU* to guarantee
#    runtime compatibility with Nuke 14/15/16 CatFileCreator (Torch-1.12.x).

name: Package TorchScript Model
on:
  workflow_dispatch:

jobs:
  export-torchscript:
    runs-on: ubuntu-latest

    steps:
    # 1) Pull repo (only needed if you keep the workflow inside your fork of Prior-Depth-Anything)
    - name: Checkout repository
      uses: actions/checkout@v4

    # 2) Python 3.9 + Torch 1.12.1 (CPU build)
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.9"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        # Torch + TorchVision (CPU wheels) – keep these versions for Nuke compatibility
        pip install torch==1.12.1+cpu torchvision==0.13.1+cpu \
          --index-url https://download.pytorch.org/whl/cpu
        # Prior-Depth-Anything repo (pulls tiny deps such as timm)
        pip install "git+https://github.com/SpatialVision/Prior-Depth-Anything.git"

    # 3) Grab the checkpoint from Hugging Face
    - name: Download pretrained weights
      run: |
        mkdir -p checkpoints
        wget -O checkpoints/prior_depth_anything_vitb.pth \
          https://huggingface.co/Rain729/Prior-Depth-Anything/resolve/main/prior_depth_anything_vitb.pth

    # 4) Convert to TorchScript (.pt) – all on CPU
    - name: Export TorchScript
      run: |
        python - <<'PY'
        import torch
        from prior_depth_anything import PriorDepthAnything

        ckpt_path = "checkpoints/prior_depth_anything_vitb.pth"

        # Build architecture
        model = PriorDepthAnything(
            device="cpu",
            frozen_model_size="vitb",
            conditioned_model_size="vitb",
            coarse_only=False,
        )
        model.load_state_dict(torch.load(ckpt_path, map_location="cpu"), strict=False)
        model.eval()

        # Strip everything except the depth tensor
        class DepthOnly(torch.nn.Module):
            def __init__(self, core):
                super().__init__()
                self.core = core
            def forward(self, x):
                out = self.core.depth_estimator(x)
                if isinstance(out, dict):
                    out = out["predicted_depth"]
                return out

        scripted = torch.jit.script(DepthOnly(model))
        scripted.save("prior_depth_anything_vitb.pt")
        PY

    # 5) Upload the .pt so you can download it and build the .cat inside Nuke
    - name: Upload TorchScript artifact
      uses: actions/upload-artifact@v4
      with:
        name: prior_depth_anything_vitb_pt
        path: prior_depth_anything_vitb.pt
